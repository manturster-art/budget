import streamlit as st
import pandas as pd
from curl_cffi import requests
from bs4 import BeautifulSoup
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# ---------------------------------------------------------
# ê¸°ë³¸ ì›¹í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(page_title="ì§€ë°©ì¬ì •365 í¬ë¡¤ëŸ¬", page_icon="ğŸ›ï¸", layout="wide")
st.title("ğŸ›ï¸ ì§€ë°©ì¬ì •365 ì„¸ë¶€ì‚¬ì—… ë°ì´í„° ìˆ˜ì§‘ê¸°")
st.markdown("""
ì´ ì›¹ í”„ë¡œê·¸ë¨ì€ ì§€ë°©ì¬ì •365 ë‚´ë¶€ APIë¥¼ í™œìš©í•˜ì—¬ ì›í•˜ëŠ” ì§€ì—­ì˜ ì„¸ë¶€ì‚¬ì—… ëª©ë¡ê³¼ ì‚¬ì—…ê°œìš” í…ìŠ¤íŠ¸ë¥¼ **ì´ˆê³ ì† ë³‘ë ¬ ì²˜ë¦¬**ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
""")

tab1, tab2 = st.tabs(["[1ë‹¨ê³„] ì‚¬ì—…ëª©ë¡ ë° ê²°ì‚°ì•¡ ì¶”ì¶œ", "[2ë‹¨ê³„] ì‚¬ì—…ê°œìš” í…ìŠ¤íŠ¸ ì¶”ì¶œ"])

# ---------------------------------------------------------
# [1ë‹¨ê³„ í—¬í¼ í•¨ìˆ˜] íŠ¹ì • ì§€ìì²´ ë°ì´í„°ë¥¼ ëê¹Œì§€ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜
# ---------------------------------------------------------
def fetch_region_data(region, year, api_key):
    laf_cd = str(region['ìì¹˜ë‹¨ì²´ì½”ë“œ'])
    laf_nm = str(region['ìì¹˜ë‹¨ì²´ëª…'])
    api_url = "https://www.lofin365.go.kr/lf/hub/QWGJK"
    
    region_data = []
    pIndex = 1
    
    while True:
        payload = {
            'Key': api_key, 'Type': 'json', 'pIndex': pIndex, 'pSize': 1000,
            'fyr': year, 'laf_cd': laf_cd, 'exe_ymd': f"{year}1231"
        }
        try:
            response = requests.get(api_url, params=payload, impersonate="chrome", timeout=15)
            data = response.json()
            
            try:
                items = data['QWGJK'][1]['row']
            except (KeyError, IndexError):
                items = []
                
            if not items: break
                
            for item in items:
                region_data.append({
                    'íšŒê³„ì—°ë„': item.get('fyr'),
                    'ì§€ìì²´ì½”ë“œ': item.get('laf_cd'),
                    'ì§€ìì²´ëª…': item.get('laf_hg_nm'),
                    'ì„¸ë¶€ì‚¬ì—…ì½”ë“œ': item.get('dbiz_cd'),
                    'ì„¸ë¶€ì‚¬ì—…ëª…': item.get('dbiz_nm'),
                    'ì˜ˆì‚°í˜„ì•¡': item.get('bdg_cash_amt', 0),
                    'ì§€ì¶œì•¡': item.get('ep_amt', 0)
                })
            
            if len(items) < 1000: break
            pIndex += 1
            time.sleep(0.1) 
            
        except Exception as e:
            break
            
    return region_data, laf_nm

# ---------------------------------------------------------
# [1ë‹¨ê³„] ì‚¬ì—…ëª©ë¡ ì¶”ì¶œ UI
# ---------------------------------------------------------
with tab1:
    st.header("1. íƒ€ê²Ÿ ì‚¬ì—…ëª©ë¡ ì§€ì—­ë³„ ì¶”ì¶œ (ë³‘ë ¬)")
    st.info("ì§€ì—­ì½”ë“œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì›í•˜ëŠ” 'ê´‘ì—­ ë‹¨ìœ„(ì‹œ/ë„)'ë¥¼ ì„ íƒí•˜ì—¬ ì´ˆê³ ì†ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    
    col1, col2 = st.columns(2)
    with col1:
        api_key = st.text_input("API ì¸ì¦í‚¤ (Decoding Key)", type="password")
    with col2:
        years_list = [str(y) for y in range(2016, 2026)]
        target_year = st.selectbox("ì¡°íšŒí•  íšŒê³„ì—°ë„", years_list, index=len(years_list)-3)
        
    region_file = st.file_uploader("ğŸ—ºï¸ ì§€ì—­ì½”ë“œ íŒŒì¼ ì—…ë¡œë“œ (ì˜ˆ: code_2024.csv)", type=['csv', 'xlsx'])
    
    # ğŸŒŸ ì§€ì—­ ì„ íƒ ë³€ìˆ˜ ì´ˆê¸°í™”
    selected_sido = []
    df_region = pd.DataFrame()
    
    # íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ì¦‰ì‹œ ì½ì–´ì„œ ê´‘ì—­ë‹¨ìœ„ ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤!
    if region_file is not None:
        try:
            if region_file.name.endswith('.csv'):
                df_region = pd.read_csv(region_file, header=1)
            else:
                df_region = pd.read_excel(region_file, header=1)
                
            if 'ì§€ì—­' in df_region.columns:
                unique_sido = df_region['ì§€ì—­'].dropna().unique().tolist()
                # ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì§€ì—­ë§Œ ë‹¤ì¤‘ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ UI ì œê³µ (ê¸°ë³¸ê°’: ì „ì²´ ì„ íƒ)
                selected_sido = st.multiselect("ğŸ“ ìˆ˜ì§‘í•  ê´‘ì—­ ë‹¨ìœ„ ì„ íƒ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)", unique_sido, default=unique_sido)
            else:
                st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì— 'ì§€ì—­' ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ì§€ìì²´ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    if st.button("ğŸš€ 1ë‹¨ê³„ ì„ íƒ ì§€ì—­ ì¶”ì¶œ ì‹œì‘", key="btn_step1"):
        if not api_key:
            st.error("API ì¸ì¦í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif region_file is None:
            st.error("ì§€ì—­ì½”ë“œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
        elif 'ìì¹˜ë‹¨ì²´ì½”ë“œ' not in df_region.columns:
            st.error("ì—…ë¡œë“œí•œ íŒŒì¼ì— 'ìì¹˜ë‹¨ì²´ì½”ë“œ' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        elif 'ì§€ì—­' in df_region.columns and not selected_sido:
            st.error("ìˆ˜ì§‘í•  ê´‘ì—­ ë‹¨ìœ„ë¥¼ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("ì„ íƒí•˜ì‹  ì§€ì—­ì˜ ë³‘ë ¬ ì¶”ì¶œì„ ì¤€ë¹„í•©ë‹ˆë‹¤..."):
                # ì„ íƒí•œ ê´‘ì—­ ë‹¨ìœ„ë§Œ í•„í„°ë§!
                if selected_sido:
                    df_region_filtered = df_region[df_region['ì§€ì—­'].isin(selected_sido)]
                else:
                    df_region_filtered = df_region
                    
                unique_regions = df_region_filtered[['ìì¹˜ë‹¨ì²´ì½”ë“œ', 'ìì¹˜ë‹¨ì²´ëª…']].drop_duplicates().to_dict('records')
                st.success(f"ì´ {len(unique_regions)}ê°œì˜ ì§€ìì²´ ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤! (ë³‘ë ¬ ì—”ì§„ ê°€ë™)")
                
                target_list = []
                prog_bar_1 = st.progress(0)
                status_1 = st.empty()
                completed_count = 0
                
                with ThreadPoolExecutor(max_workers=10) as executor:
                    futures = [executor.submit(fetch_region_data, region, target_year, api_key) for region in unique_regions]
                    
                    for future in as_completed(futures):
                        result_data, region_name = future.result()
                        if result_data:
                            target_list.extend(result_data)
                            
                        completed_count += 1
                        prog_bar_1.progress(int((completed_count / len(unique_regions)) * 100))
                        status_1.text(f"ë³‘ë ¬ ìˆ˜ì§‘ ì¤‘... [{completed_count}/{len(unique_regions)}] '{region_name}' ìˆ˜ì§‘ ì™„ë£Œ")
                        time.sleep(0.05)
                
                if target_list:
                    df_step1 = pd.DataFrame(target_list).drop_duplicates(subset=['íšŒê³„ì—°ë„', 'ì§€ìì²´ì½”ë“œ', 'ì„¸ë¶€ì‚¬ì—…ì½”ë“œ'])
                    status_1.text("âœ… ì„ íƒ ì§€ì—­ ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
                    st.success(f"ğŸ‰ ì´ {len(df_step1)}ê±´ì˜ ì‚¬ì—… ëª©ë¡ì„ ì´ˆê³ ì†ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!")
                    st.dataframe(df_step1.head(10)) 
                    
                    csv_step1 = df_step1.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                    # ì €ì¥í•  íŒŒì¼ ì´ë¦„ì— ì„ íƒí•œ ì§€ì—­ì„ í‘œì‹œí•´ ì¤ë‹ˆë‹¤.
                    region_tag = "ì „ì²´" if len(selected_sido) > 3 else "_".join(selected_sido)
                    st.download_button(
                        label="ğŸ“¥ 1ë‹¨ê³„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                        data=csv_step1,
                        file_name=f"target_list_{region_tag}_{target_year}.csv",
                        mime="text/csv"
                    )
                else:
                    st.warning("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ---------------------------------------------------------
# [2ë‹¨ê³„ í—¬í¼ í•¨ìˆ˜] ì‚¬ì—…ê°œìš” í…ìŠ¤íŠ¸ ì¶”ì¶œ
# ---------------------------------------------------------
def extract_clean_text(html_text, target_keyword):
    soup = BeautifulSoup(html_text, 'html.parser')
    raw_text = soup.get_text(separator='|', strip=True)
    parts = raw_text.split('|')
    
    stop_words = ['ì‚¬ì—…ëª©ì ', 'ì‚¬ì—…ê¸°ê°„', 'ì´ì‚¬ì—…ë¹„', 'ì‚¬ì—…ê·œëª¨', 'ì‚¬ì—…ë‚´ìš©', 'ì§€ì›í˜•íƒœ', 'ì§€ì›ì¡°ê±´', 'ì‚¬ì—…ìœ„ì¹˜', 'ì‹œí–‰ì£¼ì²´', 'ì¶”ì§„ê·¼ê±°', 'ì¶”ì§„ê²½ìœ„', 'ì¶”ì§„ê³„íš', 'ì†Œìš”ì¬ì›', 'ì›”ë³„ë°°ì •ì•¡', 'ê³¼ê±°ì§‘í–‰í˜„í™©', 'ì§€ì¶œí˜„í™©']
    extracted, found = [], False
    
    for piece in parts:
        piece = piece.strip()
        if not piece: continue
        is_stop_word = any(piece.replace(" ", "").startswith(sw) for sw in stop_words)
        if not found:
            if target_keyword.replace(" ", "") in piece.replace(" ", ""):
                found = True
                content = piece.split(target_keyword)[-1].replace(":", "").replace("ï¼š", "").strip()
                if content: extracted.append(content)
        else:
            if is_stop_word: break
            if piece not in [':', 'ï¼š', '-', '+']: extracted.append(piece)
    return " ".join(extracted).strip()

def fetch_text_data(row):
    year = str(row.get('íšŒê³„ì—°ë„', row.get('fyr')))
    laf_cd = str(row.get('ì§€ìì²´ì½”ë“œ', row.get('lafCd', row.get('laf_cd'))))
    dbiz_cd = str(row.get('ì„¸ë¶€ì‚¬ì—…ì½”ë“œ', row.get('dbizCd', row.get('dbiz_cd'))))
    
    url = "https://www.lofin365.go.kr/lf/lnncGramStst/laf/exeSvi/retvDtlsBybsnAneSituDts.do"
    payload = {
        'menuUrl': '/lf/lnncGramStst/laf/exeSvi/retvDtlsBybsnAneSituDts.do',
        'menuNm': 'ì„¸ë¶€ì‚¬ì—…ë³„ ì„¸ì¶œí˜„í™© ìƒì„¸', 'menuParaCn': 'STST', 'menuId': 'LF3120204',
        'uprMenuId': 'LF3120202', 'sysDvCd': '', 'logReg': 'true',
        'dbizCd': dbiz_cd, 'lafCd': laf_cd, 'fyr': year, 'inqYmd': f"{year}1231"
    }
    
    try:
        response = requests.post(url, data=payload, impersonate="chrome", timeout=15)
        return {
            'íšŒê³„ì—°ë„': year, 'ì§€ìì²´ì½”ë“œ': laf_cd, 'ì„¸ë¶€ì‚¬ì—…ì½”ë“œ': dbiz_cd,
            'ì‚¬ì—…ëª©ì ': extract_clean_text(response.text, 'ì‚¬ì—…ëª©ì '),
            'ì‚¬ì—…ê¸°ê°„': extract_clean_text(response.text, 'ì‚¬ì—…ê¸°ê°„'),
            'ì‚¬ì—…ë‚´ìš©': extract_clean_text(response.text, 'ì‚¬ì—…ë‚´ìš©'),
            'ì¶”ì§„ê³„íš': extract_clean_text(response.text, 'ì¶”ì§„ê³„íš')
        }
    except Exception:
        return None

# ---------------------------------------------------------
# [2ë‹¨ê³„] ì‚¬ì—…ê°œìš” í…ìŠ¤íŠ¸ ì¶”ì¶œ UI
# ---------------------------------------------------------
with tab2:
    st.header("2. ì‚¬ì—…ê°œìš” í…ìŠ¤íŠ¸ ë³‘ë ¬ ì¶”ì¶œ")
    st.info("1ë‹¨ê³„ì—ì„œ ë½‘ì€ 'ì‚¬ì—…ëª©ë¡(CSV)'ì„ ì—…ë¡œë“œí•˜ë©´ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ˆê³ ì†ìœ¼ë¡œ ê¸ì–´ì˜µë‹ˆë‹¤.")
    
    uploaded_file = st.file_uploader("ğŸ“‚ 1ë‹¨ê³„ ê²°ê³¼ íŒŒì¼(CSV) ì—…ë¡œë“œ", type=['csv'])
    
    if uploaded_file is not None:
        df_uploaded = pd.read_csv(uploaded_file)
        st.write(f"ì´ **{len(df_uploaded)}**ê±´ì˜ ë°ì´í„°ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
        
        if st.button("ğŸš€ 2ë‹¨ê³„ í…ìŠ¤íŠ¸ ë³‘ë ¬ ì¶”ì¶œ ì‹œì‘"):
            target_records = df_uploaded.to_dict('records')
            extracted_texts = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            with ThreadPoolExecutor(max_workers=10) as executor:
                futures = [executor.submit(fetch_text_data, row) for row in target_records]
                
                for i, future in enumerate(as_completed(futures), 1):
                    result = future.result()
                    if result:
                        extracted_texts.append(result)
                    
                    progress = int((i / len(target_records)) * 100)
                    progress_bar.progress(progress)
                    status_text.text(f"ì¶”ì¶œ ì§„í–‰ ì¤‘... ({i} / {len(target_records)} ê±´ ì™„ë£Œ)")
                    time.sleep(0.02)
            
            if extracted_texts:
                df_result = pd.DataFrame(extracted_texts)
                for col in ['íšŒê³„ì—°ë„', 'ì§€ìì²´ì½”ë“œ', 'ì„¸ë¶€ì‚¬ì—…ì½”ë“œ']:
                    if col in df_uploaded.columns and col in df_result.columns:
                        df_uploaded[col] = df_uploaded[col].astype(str)
                        df_result[col] = df_result[col].astype(str)
                        
                df_final = pd.merge(df_uploaded, df_result, on=['íšŒê³„ì—°ë„', 'ì§€ìì²´ì½”ë“œ', 'ì„¸ë¶€ì‚¬ì—…ì½”ë“œ'], how='left')
                
                status_text.text("âœ… ì¶”ì¶œ ì™„ë£Œ!")
                st.success("ğŸ‰ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë³‘í•©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.dataframe(df_final.head(5))
                
                csv_final = df_final.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ìµœì¢… í†µí•© ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv_final,
                    file_name="budget_text_final_custom_parallel.csv",
                    mime="text/csv"
                )
